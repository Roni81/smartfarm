{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1zEozfSJPhbHF1Ybb5SoNG97z6pVUjv2W",
      "authorship_tag": "ABX9TyMBdaukFgRytBXj6I5UiOth",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roni81/smartfarm/blob/main/growing1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afHg3oMChCQo",
        "outputId": "359eb4c6-b50c-4234-8531-2cb038cc7a51"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec 24 20:38:08 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0              48W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMH4vmYwhFc_",
        "outputId": "a4aa5117-7f18-497c-c3d7-ec768ed7076f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ksyfpE-YNVDm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, concatenate, Conv2D, MaxPooling2D, Flatten, LSTM, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 경로 설정\n",
        "image_paths = glob(\"/content/drive/MyDrive/growing2_temp/growing2_temp/images/*.jpg\")\n",
        "metadata_path = \"/content/drive/MyDrive/growing2_temp/growing2_temp/metas/*.csv\"\n",
        "labels_path = \"/content/drive/MyDrive/growing2_temp/growing2_temp/combined_dataset.csv\"\n"
      ],
      "metadata": {
        "id": "yz67NoHwNZKw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터 로드 및 전처리\n",
        "def load_images(image_paths):\n",
        "    images = [cv2.imread(img_path) for img_path in image_paths]\n",
        "    images = np.array(images) / 255.0  # 정규화\n",
        "    return images\n",
        "\n",
        "# 메타데이터 및 라벨 데이터 로드\n",
        "def load_metadata_and_labels(metadata_path, labels_path):\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    labels = pd.read_csv(labels_path)\n",
        "    return metadata, labels"
      ],
      "metadata": {
        "id": "iE6ErJO9X0jB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지, 메타데이터, 라벨 로드\n",
        "images = load_images(image_paths)\n",
        "metadata, labels = load_metadata_and_labels(metadata_path, labels_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V8bNBRZX5Wh",
        "outputId": "0c20adc5-b1c8-4f3b-dc53-1c85ca9b0392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-21cc06f1c1bb>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  images = np.array(images) / 255.0  # 정규화\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN RNN 앙상블"
      ],
      "metadata": {
        "id": "xjl7dpznhW-V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oGaDtyEchlbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 CNN 모델\n",
        "image_input = Input(shape=(height, width, channels))\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "maxpool1 = MaxPooling2D((2, 2))(conv1)\n",
        "flatten1 = Flatten()(maxpool1)\n",
        "\n",
        "# 메타데이터 RNN 모델\n",
        "meta_input = Input(shape=(num_metadata_features,))\n",
        "embedding = Embedding(input_dim=num_categories, output_dim=embedding_dim)(meta_input)\n",
        "lstm1 = LSTM(64)(embedding)\n",
        "\n",
        "# 모델 병합\n",
        "merged = concatenate([flatten1, lstm1])\n",
        "dense1 = Dense(128, activation='relu')(merged)\n",
        "output = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "model = Model(inputs=[image_input, meta_input], outputs=output)\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit([X_image_train, X_meta_train],\n",
        "          to_categorical(y_train),\n",
        "          epochs=10, batch_size=32,\n",
        "          validation_data=([X_image_val, X_meta_val], to_categorical(y_val)))"
      ],
      "metadata": {
        "id": "_o5eIj1uX86J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict([X_image_val, X_meta_val])"
      ],
      "metadata": {
        "id": "eK7Ya3eEiyce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN_LSTM"
      ],
      "metadata": {
        "id": "CbDlCKsFh1QK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dU9hMGQ6ix2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 CNN 모델\n",
        "image_input = Input(shape=(height, width, channels))\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "maxpool1 = MaxPooling2D((2, 2))(conv1)\n",
        "flatten1 = Flatten()(maxpool1)\n",
        "\n",
        "# 메타데이터 LSTM 모델\n",
        "meta_input = Input(shape=(num_metadata_features,))\n",
        "embedding = Embedding(input_dim=num_categories, output_dim=embedding_dim)(meta_input)\n",
        "lstm1 = LSTM(64)(embedding)\n",
        "\n",
        "# 모델 병합\n",
        "merged = concatenate([flatten1, lstm1])\n",
        "dense1 = Dense(128, activation='relu')(merged)\n",
        "output = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "model = Model(inputs=[image_input, meta_input], outputs=output)\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit([X_image_train, X_meta_train],\n",
        "          to_categorical(y_train),\n",
        "          epochs=10, batch_size=32,\n",
        "          validation_data=([X_image_val, X_meta_val], to_categorical(y_val)))"
      ],
      "metadata": {
        "id": "pazjEzFAh1p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi_Modal Neural Network"
      ],
      "metadata": {
        "id": "uu720NJsh14K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HP9_CrzPiH1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Um0LLHth2D4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}