{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "mount_file_id": "1zEozfSJPhbHF1Ybb5SoNG97z6pVUjv2W",
      "authorship_tag": "ABX9TyP//RHQ8FagXrjhX/GTHuoa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roni81/smartfarm/blob/main/growing1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqpR4-KWmK0Z",
        "outputId": "406650da-1463-4b9d-a4df-13eb662c713c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "\n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li32Lw6UmWTz",
        "outputId": "8e4ab084-de7b-4406-daff-71dea154756f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "1.3761647179999272\n",
            "GPU (s):\n",
            "0.07323069399990345\n",
            "GPU speedup over CPU: 18x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afHg3oMChCQo",
        "outputId": "8c6e8b02-3f52-4d80-832e-2a9a1748aaa1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Dec 24 21:57:49 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0              41W / 300W |   1420MiB / 16384MiB |      4%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMH4vmYwhFc_",
        "outputId": "f1860f4e-25b8-49ec-fe8a-3342d68cf301"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ksyfpE-YNVDm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, concatenate, Conv2D, MaxPooling2D, Flatten, LSTM, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yz67NoHwNZKw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def resize_images(input_folder, output_folder, target_size):\n",
        "    # 출력 폴더가 없다면 생성\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # 입력 폴더에서 이미지 파일 경로 리스트 가져오기\n",
        "    image_paths = [os.path.join(input_folder, file) for file in os.listdir(input_folder) if file.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    # 각 이미지에 대해 크기 조정 및 저장\n",
        "    for image_path in image_paths:\n",
        "        # 이미지 읽기\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # 이미지가 비어 있지 않은지 확인\n",
        "        if image is not None and not image.size == 0:\n",
        "            # 이미지 크기 조정\n",
        "            resized_image = cv2.resize(image, target_size)\n",
        "\n",
        "            # 출력 폴더에 조정된 이미지 저장\n",
        "            output_path = os.path.join(output_folder, os.path.basename(image_path))\n",
        "            cv2.imwrite(output_path, resized_image)\n",
        "        else:\n",
        "            print(f\"이미지를 읽거나 크기를 조정할 수 없습니다: {image_path}\")\n",
        "\n",
        "# 예시: 입력 폴더, 출력 폴더, 타겟 크기 설정\n",
        "input_folder = \"/content/drive/MyDrive/growing2_temp/growing2_temp/images\"\n",
        "output_folder = \"/content/drive/MyDrive/growing2_temp/growing2_temp/images_resized\"\n",
        "target_size = (1000, 750)  # 원하는 크기로 변경\n",
        "\n",
        "# 이미지 크기 조정 실행\n",
        "resize_images(input_folder, output_folder, target_size)"
      ],
      "metadata": {
        "id": "wVC5biuIojDd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터 로드 및 전처리\n",
        "def load_images_and_metadata(image_paths, metadata_folder):\n",
        "    images = []\n",
        "    metadata_list = []\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        # 이미지 읽기\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # 이미지가 성공적으로 로드되었는지 확인\n",
        "        if img is not None:\n",
        "            # 이미지 정규화 및 리스트에 추가\n",
        "            img = img / 255.0\n",
        "            images.append(img)\n",
        "\n",
        "            # 이미지 파일 이름에서 식별자 추출 (예: 이미지 파일이름이 '123.jpg'이면 식별자는 '123')\n",
        "            identifier = os.path.splitext(os.path.basename(img_path))[0]\n",
        "\n",
        "            # 식별자를 사용하여 메타데이터 파일 찾기 및 읽기\n",
        "            metadata_file_path = os.path.join(metadata_folder, f\"{identifier}.csv\")\n",
        "            metadata = pd.read_csv(metadata_file_path)\n",
        "            metadata_list.append(metadata)\n",
        "        else:\n",
        "            print(f\"경고: {img_path}에서 이미지를 읽을 수 없습니다.\")\n",
        "\n",
        "    # 이미지 데이터와 메타데이터를 연결\n",
        "    images = np.array(images)\n",
        "    metadata = pd.concat(metadata_list, ignore_index=True)\n",
        "\n",
        "    return images, metadata\n",
        "# 메타데이터 및 라벨 데이터 로드\n",
        "def load_labels(labels_path):\n",
        "    labels = pd.read_csv(labels_path)\n",
        "    return labels"
      ],
      "metadata": {
        "id": "iE6ErJO9X0jB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 경로 설정\n",
        "image_paths = glob(\"/content/drive/MyDrive/growing2_temp/growing2_temp/images_resized/*.jpg\")\n",
        "labels_path = \"/content/drive/MyDrive/growing2_temp/growing2_temp/combined_dataset.csv\"\n",
        "metadata_folder = \"/content/drive/MyDrive/growing2_temp/growing2_temp/metas/\"\n",
        "\n"
      ],
      "metadata": {
        "id": "2si2GfYmw5GK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지, 메타데이터, 라벨 로드\n",
        "images, metas = load_images_and_metadata(image_paths, metadata_folder)\n",
        "labels = load_metadata_and_labels(labels_path)\n"
      ],
      "metadata": {
        "id": "6V8bNBRZX5Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN RNN 앙상블"
      ],
      "metadata": {
        "id": "xjl7dpznhW-V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oGaDtyEchlbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 CNN 모델\n",
        "image_input = Input(shape=(height, width, channels))\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "maxpool1 = MaxPooling2D((2, 2))(conv1)\n",
        "flatten1 = Flatten()(maxpool1)\n",
        "\n",
        "# 메타데이터 RNN 모델\n",
        "meta_input = Input(shape=(num_metadata_features,))\n",
        "embedding = Embedding(input_dim=num_categories, output_dim=embedding_dim)(meta_input)\n",
        "lstm1 = LSTM(64)(embedding)\n",
        "\n",
        "# 모델 병합\n",
        "merged = concatenate([flatten1, lstm1])\n",
        "dense1 = Dense(128, activation='relu')(merged)\n",
        "output = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "model = Model(inputs=[image_input, meta_input], outputs=output)\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit([X_image_train, X_meta_train],\n",
        "          to_categorical(y_train),\n",
        "          epochs=10, batch_size=32,\n",
        "          validation_data=([X_image_val, X_meta_val], to_categorical(y_val)))"
      ],
      "metadata": {
        "id": "_o5eIj1uX86J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict([X_image_val, X_meta_val])"
      ],
      "metadata": {
        "id": "eK7Ya3eEiyce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN_LSTM"
      ],
      "metadata": {
        "id": "CbDlCKsFh1QK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dU9hMGQ6ix2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 CNN 모델\n",
        "image_input = Input(shape=(height, width, channels))\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "maxpool1 = MaxPooling2D((2, 2))(conv1)\n",
        "flatten1 = Flatten()(maxpool1)\n",
        "\n",
        "# 메타데이터 LSTM 모델\n",
        "meta_input = Input(shape=(num_metadata_features,))\n",
        "embedding = Embedding(input_dim=num_categories, output_dim=embedding_dim)(meta_input)\n",
        "lstm1 = LSTM(64)(embedding)\n",
        "\n",
        "# 모델 병합\n",
        "merged = concatenate([flatten1, lstm1])\n",
        "dense1 = Dense(128, activation='relu')(merged)\n",
        "output = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "model = Model(inputs=[image_input, meta_input], outputs=output)\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit([X_image_train, X_meta_train],\n",
        "          to_categorical(y_train),\n",
        "          epochs=10, batch_size=32,\n",
        "          validation_data=([X_image_val, X_meta_val], to_categorical(y_val)))"
      ],
      "metadata": {
        "id": "pazjEzFAh1p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi_Modal Neural Network"
      ],
      "metadata": {
        "id": "uu720NJsh14K"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HP9_CrzPiH1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Um0LLHth2D4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}